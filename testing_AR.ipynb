{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "from transformers import BertForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file test the first version of the model: classification with context\n",
    "\n",
    "PRETRAINED_MODEL_NAME = '/home/daril_kw/data/savings_for_60_rows/model_before_training_opti_full_for_para_60'\n",
    "\n",
    "DATALOADER_DIR = \"/home/daril_kw/data/savings_for_60_rows/test_dataloader_60.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we evaluate\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load the prediction_dataloader\n",
    "prediction_dataloader = torch.load(DATALOADER_DIR)\n",
    "\n",
    "\n",
    "# we load the model\n",
    "model = BertForSequenceClassification.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "model.to(device)\n",
    "print(\"we evaluate\")\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables\n",
    "predictions, true_labels, list_inputs_test = [], [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first batch in the prediction_dataloader\n",
    "\n",
    "first_batch = next(iter(prediction_dataloader))\n",
    "first_batch # this is a tuple of 3 elements: input_ids, attention_mask, labels\n",
    "# first_batch[0].shape, first_batch[1].shape, first_batch[2].shape\n",
    "first_batch = tuple(t.to(device) for t in first_batch) # we put the batch on the device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101, 29308,   128,  ...,     0,     0,     0],\n",
       "         [  101, 29174,   128,  ...,     0,     0,     0],\n",
       "         [  101, 29125,   128,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101, 29282,   128,  ...,     0,     0,     0],\n",
       "         [  101, 29850,   128,  ...,     0,     0,     0],\n",
       "         [  101, 29725,   128,  ...,     0,     0,     0]], device='cuda:0'),\n",
       " tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.]], device='cuda:0'),\n",
       " tensor([39, 34, 18, 14, 12, 48, 10,  0,  9, 40, 42, 36], device='cuda:0'))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_input_ids, b_input_mask, b_labels = first_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 29308,   128,  ...,     0,     0,     0],\n",
       "        [  101, 29174,   128,  ...,     0,     0,     0],\n",
       "        [  101, 29125,   128,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101, 29282,   128,  ...,     0,     0,     0],\n",
       "        [  101, 29850,   128,  ...,     0,     0,     0],\n",
       "        [  101, 29725,   128,  ...,     0,     0,     0]], device='cuda:0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# move the batch to the device because we are using the GPU. the previous instruction tuple(t.to(device) for t in first_batch) is just a short cut for this\n",
    "b_input_ids = b_input_ids.to(device)\n",
    "b_input_mask = b_input_mask.to(device)\n",
    "b_labels = b_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 29308,   128,  ...,     0,     0,     0],\n",
       "        [  101, 29174,   128,  ...,     0,     0,     0],\n",
       "        [  101, 29125,   128,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101, 29282,   128,  ...,     0,     0,     0],\n",
       "        [  101, 29850,   128,  ...,     0,     0,     0],\n",
       "        [  101, 29725,   128,  ...,     0,     0,     0]], device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference time:  0.03991341590881348\n"
     ]
    }
   ],
   "source": [
    "# We will compute the inference time\n",
    "import time\n",
    "t0 = time.time()\n",
    "with torch.no_grad():\n",
    "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    logits = outputs[0]\n",
    "t1 = time.time()\n",
    "infer_time = t1-t0\n",
    "print(\"inference time: \", infer_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One trajectory inference time: 0.003326117992401123\n",
      " Total inference time for 300 points: 0.9978353977203369\n"
     ]
    }
   ],
   "source": [
    "# Then for one trajectory, the inference time is \n",
    "trajectory_inference_time = infer_time/len(b_input_ids)\n",
    "# If we have 300 points in the trajectory, the inference time is 300*trajectory_inference_time\n",
    "print(f\"One trajectory inference time: {trajectory_inference_time}\\n Total inference time for 300 points: {300*trajectory_inference_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details of the outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1756,  0.0554, -0.2076,  ..., -0.3755,  0.3280, -0.0929],\n",
       "        [ 0.1270,  0.0911, -0.2356,  ..., -0.4460,  0.2182, -0.0972],\n",
       "        [ 0.1986,  0.1220, -0.2504,  ..., -0.4339,  0.1873,  0.0108],\n",
       "        ...,\n",
       "        [ 0.1416,  0.1100, -0.2492,  ..., -0.4008,  0.2238, -0.1127],\n",
       "        [ 0.1544,  0.2864, -0.3465,  ..., -0.3810,  0.1673, -0.1443],\n",
       "        [ 0.1566,  0.1921, -0.4025,  ..., -0.3802,  0.1699, -0.0809]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The outputs are the logits(=scores) for each class. We take the class with the highest score as the prediction\n",
    "# For each input, we take the class with the highest score as the prediction\n",
    "logits #logits means the scores for each class. Then if we have 10 classes, we have 10 scores for each input\n",
    "# For example \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.7556e-01,  5.5411e-02, -2.0764e-01, -5.3356e-02, -4.8283e-01,\n",
       "         3.9959e-01,  2.4936e-01, -6.1580e-02,  1.2208e+00,  8.8233e-01,\n",
       "         7.9652e-02, -9.1809e-01, -6.1648e-01,  2.2795e-02, -4.9137e-01,\n",
       "         2.5167e-02,  5.0348e-01,  8.9886e-01,  5.3918e-01,  4.7088e-01,\n",
       "        -2.3605e-01,  3.0360e-01,  6.9202e-01, -2.3386e-01,  4.7819e-01,\n",
       "         6.2067e-01, -2.8057e-01,  5.3282e-01, -1.3414e-01,  7.5720e-02,\n",
       "         2.0141e-01, -7.7584e-01, -3.0211e-01,  3.8304e-02, -2.9572e-01,\n",
       "        -3.7977e-01, -2.4700e-01, -6.0180e-01,  6.9280e-01, -7.9707e-01,\n",
       "        -1.0991e+00, -6.2875e-02,  2.0101e-01,  2.4983e-01,  1.3069e-01,\n",
       "        -1.1322e-01, -2.4029e-01, -4.3113e-02, -4.4805e-01,  1.3670e-01,\n",
       "         5.0791e-02,  5.8126e-03,  1.4891e-01,  1.6357e-01, -6.0650e-03,\n",
       "        -7.7350e-02, -3.3025e-01, -3.7892e-01, -2.1078e-01,  1.2388e-01,\n",
       "        -7.3392e-01,  5.1020e-01, -3.2051e-02, -3.1992e-01, -5.2206e-01,\n",
       "        -6.3849e-01,  4.4133e-01, -4.0169e-01, -3.0162e-02, -6.0586e-01,\n",
       "         2.6853e-01, -3.4276e-02,  1.0678e-01, -2.1642e-01, -1.5569e-01,\n",
       "        -3.0145e-01, -8.7548e-01,  3.0806e-02,  5.4097e-01,  7.1822e-02,\n",
       "         1.3297e-01,  3.3222e-02, -1.5057e-01,  1.1486e+00,  8.6312e-02,\n",
       "         1.2276e-01, -8.6719e-01, -3.4830e-01,  3.0771e-01, -1.3890e-01,\n",
       "        -6.0395e-01,  2.1434e-01, -2.8035e-01,  1.2546e-01,  4.4289e-01,\n",
       "         1.3129e-01,  9.0683e-01, -4.9987e-01, -4.9253e-01,  1.4709e-01,\n",
       "         1.3734e-01, -2.8520e-01, -1.9076e-01,  4.1825e-01,  5.8412e-01,\n",
       "        -4.8480e-01,  3.1006e-01, -4.8765e-01, -6.8517e-01, -2.4492e-01,\n",
       "         4.5656e-01,  4.7951e-01, -4.1452e-01,  1.1995e-01, -1.3688e-01,\n",
       "        -1.7995e-02, -1.7417e-01, -3.0678e-01, -4.1221e-01, -9.3361e-02,\n",
       "        -3.1936e-01,  3.2692e-01,  2.6079e-01,  1.1478e-01, -4.4486e-02,\n",
       "        -6.9359e-01, -2.1669e-01, -2.4018e-01,  8.4421e-02, -4.1126e-01,\n",
       "         6.8768e-01,  4.4357e-01,  3.2826e-01, -4.4421e-01, -3.1601e-01,\n",
       "         2.5086e-01,  7.1636e-01, -1.2832e-01, -4.0847e-01, -7.9838e-01,\n",
       "        -7.5440e-01,  4.9200e-01, -3.1784e-01, -1.0421e+00,  4.0657e-01,\n",
       "        -2.7891e-01,  5.9059e-02, -4.8418e-01,  9.8212e-02, -5.5619e-01,\n",
       "         6.1352e-01,  2.6583e-01,  6.6830e-02,  3.8891e-01, -1.4602e-01,\n",
       "         2.4345e-01,  7.6539e-01, -1.8906e-02,  6.8293e-01, -3.0491e-01,\n",
       "        -4.8678e-02, -1.9095e-01,  4.0520e-01,  1.6026e-01, -3.1299e-01,\n",
       "         3.6530e-01, -7.9942e-02, -1.3456e-01,  2.1281e-01, -1.3681e-01,\n",
       "         1.9931e-01, -3.3585e-01, -6.6012e-02,  2.0996e-01, -1.1611e-01,\n",
       "         1.1362e-01, -8.1212e-03, -2.4549e-01, -1.7832e-01, -2.7974e-01,\n",
       "        -4.3159e-02,  3.6322e-02, -6.1049e-01, -1.1204e-01, -1.2419e-01,\n",
       "         2.9940e-01,  4.3063e-01,  4.5835e-01, -4.4139e-01,  1.8680e-01,\n",
       "        -1.6174e-01, -2.7892e-01, -3.4136e-01,  1.7859e-01,  3.5632e-01,\n",
       "         2.4098e-01,  5.1373e-04, -4.9368e-02,  2.2553e-01,  1.0086e+00,\n",
       "         4.0465e-01, -4.7819e-01,  4.2797e-01, -2.5159e-01, -8.9027e-02,\n",
       "         1.0030e+00,  3.9352e-01,  2.3787e-01, -8.0129e-01, -2.0702e-01,\n",
       "         3.9898e-01,  6.1205e-01,  2.5907e-01,  1.0973e-01, -2.9132e-01,\n",
       "        -4.5129e-01,  9.8934e-01, -2.3347e-02, -2.2558e-02, -5.1463e-01,\n",
       "         9.9924e-01,  3.6084e-02,  3.0638e-01,  1.1926e-01, -3.1649e-01,\n",
       "         3.3894e-01,  5.0795e-01,  7.5807e-02,  2.6590e-01,  2.9388e-01,\n",
       "        -6.7061e-02,  2.0235e-01, -1.7010e-01, -2.4241e-01, -4.6737e-01,\n",
       "        -1.0814e-01,  5.3996e-01,  2.8406e-02,  1.6384e-01, -6.6481e-01,\n",
       "        -4.5474e-04, -2.3544e-01, -6.2471e-01, -2.5635e-02, -1.5266e-01,\n",
       "         1.9734e-01,  2.0186e-01,  2.0696e-01, -3.6703e-01,  2.4412e-01,\n",
       "         7.4664e-01, -5.1147e-01, -4.1982e-01, -3.8480e-02,  2.6937e-01,\n",
       "         5.9083e-01,  5.3423e-01,  4.0197e-01, -2.8147e-01, -2.4010e-01,\n",
       "         5.3593e-01,  3.1530e-01, -1.6635e-01,  2.6100e-01, -3.8326e-01,\n",
       "        -4.4233e-01,  3.8044e-01, -1.0300e-01,  9.8663e-02, -7.2545e-01,\n",
       "         1.1744e-01, -7.5909e-01,  8.2577e-02,  7.4383e-01,  7.1091e-01,\n",
       "         5.4602e-01,  4.0809e-01,  7.9766e-01,  1.3894e-02, -2.7402e-01,\n",
       "         1.6215e-01, -3.8368e-02, -2.1020e-01, -1.6400e-01,  1.0417e+00,\n",
       "         1.5594e-01,  7.0214e-02, -3.8346e-01, -2.3373e-01,  2.7615e-01,\n",
       "        -4.7492e-01,  6.7849e-01,  2.4654e-01, -5.0333e-01, -4.2893e-01,\n",
       "        -9.4526e-01, -5.7443e-01, -3.7884e-01, -5.8291e-01, -6.9045e-01,\n",
       "        -8.0361e-01, -4.7458e-01,  1.1411e-01,  9.7892e-02,  9.4686e-01,\n",
       "         4.6363e-01, -8.4364e-02,  4.2731e-01, -9.6338e-02, -5.8791e-01,\n",
       "         6.7676e-02, -3.0580e-01,  3.9074e-01, -1.6690e-01,  1.3685e-01,\n",
       "        -9.1480e-01,  5.7427e-02, -3.1983e-01,  5.6225e-01, -1.9292e-02,\n",
       "        -6.2527e-01, -2.4423e-01, -1.0709e-01, -3.4528e-01,  8.1116e-01,\n",
       "        -1.3673e-01,  4.3820e-01,  2.4412e-01, -5.4132e-01,  3.4102e-01,\n",
       "        -1.1565e-01, -1.8187e-01, -1.7220e-01,  1.4216e-01, -6.4542e-02,\n",
       "         8.6559e-02,  3.6863e-01, -9.7336e-01,  9.3594e-02, -2.6268e-01,\n",
       "        -3.2320e-01,  5.1888e-01, -4.0968e-01, -6.8426e-01,  2.0410e-01,\n",
       "         8.4579e-02, -1.8475e-02, -3.4949e-01,  6.7481e-02,  4.3247e-01,\n",
       "        -6.2370e-01, -4.5690e-01,  3.5361e-02,  2.5115e-01, -8.4927e-01,\n",
       "        -2.9144e-01,  2.4235e-01,  3.3023e-01,  2.9386e-01, -8.8558e-01,\n",
       "        -3.6692e-01, -4.2684e-01,  8.5083e-01, -6.6042e-01, -3.5685e-01,\n",
       "         1.5263e-01,  3.5090e-01, -2.5470e-02, -1.1808e+00, -8.7448e-01,\n",
       "        -2.7009e-01, -4.4533e-01, -2.6427e-01,  1.2979e-02, -3.2794e-01,\n",
       "         3.1755e-01, -1.4430e-01,  1.4969e-01,  1.4432e-01, -5.0782e-01,\n",
       "         6.2735e-01, -3.3227e-02, -1.1643e-02,  1.0453e-01, -4.0028e-01,\n",
       "         2.2023e-01,  3.9392e-01,  1.4447e-01, -2.7296e-01,  1.5677e-01,\n",
       "         1.1569e-01,  7.0976e-01,  3.8566e-02, -9.1843e-01,  6.9922e-02,\n",
       "         1.8861e-01, -1.8155e-01,  7.8248e-02,  5.0489e-02,  6.7489e-01,\n",
       "         8.1827e-02, -2.4286e-02,  3.8955e-01,  9.0421e-01, -2.6294e-01,\n",
       "         6.4102e-01,  2.6094e-01, -2.9276e-01, -5.6385e-01, -5.0135e-01,\n",
       "        -9.9115e-01,  3.3158e-01,  2.9022e-01, -4.4413e-01, -1.3352e-01,\n",
       "         1.4500e-02,  4.0493e-01, -3.2819e-01, -1.5063e-01,  1.6459e-01,\n",
       "        -2.8879e-01,  3.6359e-01, -4.1363e-01, -5.2966e-01, -1.6896e-01,\n",
       "         2.7423e-01,  8.4204e-01,  1.0756e-01, -2.3423e-01,  8.0245e-02,\n",
       "        -5.5245e-01, -7.9403e-01,  1.1366e-01,  2.9262e-01, -6.9226e-02,\n",
       "         6.0483e-01, -3.9197e-03,  5.1337e-01,  4.6313e-01,  2.1908e-01,\n",
       "        -3.8133e-01,  9.9782e-01,  1.0848e-01,  8.6603e-01, -3.2413e-01,\n",
       "        -6.3593e-01,  5.7212e-01, -2.5771e-01,  1.1393e-01, -2.2276e-01,\n",
       "        -2.4659e-01, -1.3434e-01, -4.2443e-01, -4.8809e-02,  1.4983e-01,\n",
       "        -4.8637e-01,  2.0431e-01, -2.3187e-01, -1.6796e-01,  1.3912e-01,\n",
       "         6.2927e-01,  5.8600e-01,  8.5078e-01,  4.8634e-01, -3.4650e-01,\n",
       "         4.1280e-01,  4.2176e-01,  1.3877e-01, -1.2064e-01,  7.1369e-02,\n",
       "        -9.1183e-01,  4.8342e-02,  1.7109e-01, -5.9731e-01,  5.9407e-02,\n",
       "        -1.2340e-01,  7.0810e-01,  5.0681e-01,  4.1098e-02,  3.4696e-01,\n",
       "         2.3686e-01, -2.3824e-01, -3.3241e-02,  1.3072e-01,  2.3509e-01,\n",
       "         4.0381e-01, -6.1219e-02, -1.5497e-01,  2.3042e-01,  3.5269e-01,\n",
       "         6.4891e-01,  4.8217e-01, -1.8814e-03,  3.3202e-01,  8.7578e-02,\n",
       "        -1.9809e-01, -3.6551e-01, -8.1747e-02, -3.8202e-01,  3.1713e-01,\n",
       "         5.2457e-01, -1.0199e+00,  5.2472e-01,  1.0884e-01,  1.9886e-02,\n",
       "         1.5422e-01, -2.8227e-01, -2.4497e-01,  8.4747e-02,  3.1114e-01,\n",
       "        -5.8907e-01, -4.6696e-02,  5.3336e-01, -7.0659e-01, -3.0961e-01,\n",
       "        -4.5609e-01,  6.3726e-01, -9.7359e-02,  6.7461e-01, -3.9431e-01,\n",
       "        -3.0079e-01,  1.6127e-01,  4.5068e-01,  3.2240e-01, -2.5038e-01,\n",
       "        -5.4156e-01, -1.6533e-01, -3.9456e-01, -3.8066e-01,  5.0372e-01,\n",
       "        -3.9770e-01, -4.9276e-01, -4.5890e-01,  3.3793e-02, -7.6742e-01,\n",
       "         2.4758e-01, -4.8890e-02, -7.4075e-01, -2.7556e-01,  1.6560e-01,\n",
       "        -9.7828e-01,  1.5102e-01,  3.4310e-01, -5.5981e-02,  6.3842e-02,\n",
       "        -2.8194e-01, -7.6058e-02, -3.4941e-01, -1.7189e-01, -3.1884e-01,\n",
       "        -1.7015e-01,  1.5701e-01, -2.9620e-02, -2.9148e-01, -9.4195e-02,\n",
       "        -3.7363e-01, -4.1577e-01,  2.6737e-01,  3.8270e-01,  7.3850e-01,\n",
       "         4.9740e-01,  5.2992e-02,  1.9704e-01, -3.3954e-01,  1.2096e-01,\n",
       "        -6.4737e-02,  1.5786e-01,  3.0282e-01,  1.0601e+00, -1.2696e-01,\n",
       "         3.2075e-01,  4.9198e-01,  5.1335e-01,  5.3442e-01,  6.0619e-01,\n",
       "         2.1867e-01,  5.3793e-01, -3.9310e-02,  2.3231e-01, -6.2456e-01,\n",
       "         6.1807e-01, -5.4991e-01, -2.8880e-01,  1.8642e-01, -3.1119e-02,\n",
       "        -1.7562e-01,  4.6848e-02, -1.4592e-01, -3.8237e-01,  6.8654e-01,\n",
       "         7.0566e-01, -3.8530e-01,  3.4887e-01,  3.4876e-01,  5.3919e-01,\n",
       "         1.8559e-01,  3.9080e-02,  3.3923e-01, -3.8344e-02, -6.7280e-02,\n",
       "         8.6067e-02,  3.4094e-01,  1.7624e-01, -6.3599e-01,  4.2580e-01,\n",
       "         4.6461e-01,  6.7434e-01,  2.1582e-01, -1.8621e-01, -3.8242e-02,\n",
       "        -8.6831e-01, -7.4267e-01,  5.5787e-02,  5.3741e-01,  2.9897e-02,\n",
       "        -4.4011e-01,  2.3487e-01,  8.3507e-01,  2.2234e-01,  1.5559e-01,\n",
       "        -4.9203e-01,  3.0213e-01, -1.0343e-01,  9.3117e-03, -3.9859e-02,\n",
       "         5.0945e-01,  1.8581e-01,  1.9055e-01,  2.6467e-01, -2.0269e-01,\n",
       "        -4.9086e-01,  1.3327e-01, -4.4461e-01, -7.9340e-02,  7.7069e-02,\n",
       "        -2.2354e-01,  1.7411e-01, -6.2559e-02,  1.0097e+00, -1.8451e-01,\n",
       "         7.0357e-01,  1.6189e-01, -2.5566e-01,  3.3441e-02, -1.3780e-01,\n",
       "         2.5277e-01,  9.0037e-02,  5.9231e-01,  3.9404e-01,  8.9319e-02,\n",
       "         2.8115e-01,  3.5074e-02,  1.5121e-01,  1.5164e-01,  1.0492e-01,\n",
       "         3.4355e-01, -9.7812e-02,  3.7231e-01, -2.6351e-01,  1.3906e-01,\n",
       "         4.1346e-01,  2.4120e-01, -3.4002e-01,  7.5599e-01, -3.1205e-01,\n",
       "         1.3443e-01,  2.9005e-01,  7.1801e-02, -4.3862e-01, -4.1030e-01,\n",
       "        -8.9108e-02,  2.0394e-01,  5.0552e-01,  2.8929e-01,  8.6034e-02,\n",
       "        -4.1236e-01,  3.3669e-02, -6.2570e-01,  3.3473e-01,  8.6094e-02,\n",
       "        -9.4755e-02, -3.9800e-01, -7.5063e-02,  4.9635e-01, -1.8232e-01,\n",
       "        -4.3096e-03,  4.0936e-01, -4.1567e-01, -5.9791e-01, -2.6358e-01,\n",
       "         3.9066e-01, -4.7986e-01, -3.0167e-01, -1.8507e-01,  2.4279e-01,\n",
       "        -6.5501e-02, -2.9454e-01, -6.3647e-02,  1.8613e-01, -9.5061e-02,\n",
       "        -1.7881e-01, -7.1496e-01,  1.6839e-01,  6.7223e-01, -9.4043e-02,\n",
       "        -6.2289e-01,  8.8342e-01,  3.1419e-01,  1.1927e-02, -4.5986e-01,\n",
       "         2.2020e-01,  3.2800e-02,  3.4706e-02,  2.6344e-01, -5.4170e-01,\n",
       "         2.5255e-01,  6.5300e-01, -5.5702e-01,  7.7342e-01, -5.6933e-01,\n",
       "        -2.3784e-01,  4.0436e-01, -2.0647e-01,  2.7019e-01, -2.6436e-01,\n",
       "         1.0582e+00,  5.4077e-01,  4.7491e-01, -7.1842e-02, -4.6594e-01,\n",
       "        -3.7315e-01,  1.4965e-01, -2.6920e-01, -5.6367e-02,  3.6614e-01,\n",
       "        -5.9568e-01, -2.7478e-01, -1.2256e-01, -3.8046e-01, -5.8931e-01,\n",
       "         1.1047e-01, -1.7814e-01, -2.6233e-01, -1.5914e-01,  7.3560e-01,\n",
       "         3.3289e-01,  2.7832e-01,  8.1526e-01,  3.2093e-01,  3.3000e-02,\n",
       "         1.0217e-01,  3.6680e-01,  1.2798e-01, -4.9944e-02, -3.5280e-01,\n",
       "        -2.2068e-01,  2.2543e-01,  3.0195e-01,  1.0901e-01, -1.4413e-01,\n",
       "         4.1050e-01,  5.5599e-01,  6.7331e-01,  4.2935e-01, -2.7574e-01,\n",
       "        -7.1123e-01,  2.2395e-01,  4.9370e-01, -1.7522e-01,  5.0382e-01,\n",
       "         3.1656e-01,  1.2309e-01,  4.5637e-01,  1.8655e-02, -5.7503e-02,\n",
       "         6.0110e-02, -7.2153e-01,  2.2602e-01,  3.6687e-01, -2.9701e-01,\n",
       "         1.3922e-01,  1.9054e-02, -2.2969e-01, -1.8941e-01, -2.5780e-01,\n",
       "        -9.9887e-02,  2.2015e-01,  1.0256e-01, -9.1178e-02,  3.7235e-01,\n",
       "         7.9046e-01,  8.3053e-01,  1.9528e-01, -7.7749e-02, -4.0834e-01,\n",
       "         3.9598e-02, -2.4581e-01, -1.6316e-01, -4.9124e-01, -2.4865e-01,\n",
       "         8.8733e-02, -1.7856e-01, -2.7395e-01, -4.3005e-01,  7.0917e-01,\n",
       "        -1.3866e-01, -3.1215e-01, -7.1826e-01, -4.3265e-01,  1.9613e-01,\n",
       "         3.8819e-01, -1.0848e-01,  1.1563e+00,  1.1655e-01, -8.8289e-01,\n",
       "        -1.2135e-01, -8.7332e-02, -4.8922e-01, -2.9583e-02, -1.4492e-01,\n",
       "        -2.1678e-01,  3.7120e-01,  8.6127e-01, -5.4616e-01,  4.2159e-02,\n",
       "        -8.3580e-01,  1.7797e-01,  1.1521e+00, -4.2098e-01,  5.7480e-02,\n",
       "         2.9122e-01,  6.7680e-02,  1.3397e-01, -5.8823e-01, -2.0518e-01,\n",
       "        -6.9946e-02,  4.0055e-01,  1.3869e-01,  2.6085e-01, -1.0374e-01,\n",
       "         3.5709e-01,  6.0231e-01, -6.7486e-01, -1.9118e-01,  2.7501e-01,\n",
       "        -2.6146e-01, -4.2132e-01,  1.7871e-01,  1.9737e-01,  2.4993e-01,\n",
       "        -1.7663e-01,  3.7851e-01, -3.8763e-01,  4.2230e-01,  1.0175e-02,\n",
       "        -3.5613e-01,  4.3015e-01,  3.5513e-01, -3.4917e-02,  3.4380e-01,\n",
       "         2.4359e-02, -2.8251e-01, -3.5233e-01, -7.1256e-02, -8.6883e-01,\n",
       "        -4.3812e-01,  2.3604e-01, -1.8402e-01, -3.5722e-02, -5.8772e-01,\n",
       "        -6.7038e-02, -7.2385e-01, -5.2958e-01,  3.1063e-01, -6.3944e-01,\n",
       "        -1.1213e-01,  6.4389e-01, -1.2872e+00, -1.6742e-01, -1.0786e+00,\n",
       "        -1.2294e-01,  5.3668e-01,  6.5030e-01,  1.7157e-01, -7.9354e-02,\n",
       "         4.3879e-01, -5.6677e-01, -2.9731e-01,  2.1581e-01, -3.7551e-01,\n",
       "         3.2796e-01, -9.2935e-02], device='cuda:0')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0] # this is the scores for the first input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8ijo m7867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "892"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of classes is the number of columns in the logits\n",
    "num_classes = logits.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 892])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  8,   8, 827, 725, 725, 827, 827, 827, 725, 827, 725, 725],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each input, we take the class with the highest score as the prediction\n",
    "_, current_prediction = torch.max(logits, 1)\n",
    "current_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(current_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we add these prediction to the initial inputs and try to predict the next point.\n",
    "# We will move the sep token (102) on on position and replace it position with the predicted class.\n",
    "# For example, if we have the input [101, 5, 7, 8, 9 ,102, 0,0,0,0,0], and the predicted class is 3 then we'll have [101,5, 7,8,9,3,102,0,0,0,0] as the new input\n",
    "\n",
    "\n",
    "def add_prediction_to_input(input_ids, prediction, sep_token_id=102):\n",
    "    # we find the position of the sep token\n",
    "    sep_token_position = (input_ids == sep_token_id).nonzero(as_tuple=True)[0]\n",
    "    # we replace the sep token with the prediction\n",
    "    input_ids[sep_token_position] = prediction\n",
    "    # move the sep token to the next position\n",
    "    input_ids[sep_token_position+1] = sep_token_id\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_prediction_to_input(b_input_ids[0], current_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prediction_to_input_batch(input_ids, predictions, sep_token_id=102):\n",
    "    # new_input_ids = input_ids.clone() # if we directly modify input_ids, it will modify the original input_ids and we gain in memory\n",
    "    for i in range(len(predictions)):\n",
    "        # if the current prediction is already the sep token, we don't change the input or if there the position of the septoken is the last position\n",
    "        if predictions[i] == sep_token_id or (input_ids[i] == sep_token_id).nonzero(as_tuple=True)[0] == len(input_ids[i])-1:\n",
    "            continue\n",
    "        else:\n",
    "            input_ids[i] = add_prediction_to_input(input_ids[i], predictions[i])\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([59], device='cuda:0'), tensor([58], device='cuda:0'), tensor([34], device='cuda:0'), tensor([45], device='cuda:0'), tensor([49], device='cuda:0'), tensor([42], device='cuda:0'), tensor([39], device='cuda:0'), tensor([40], device='cuda:0'), tensor([36], device='cuda:0'), tensor([46], device='cuda:0'), tensor([71], device='cuda:0'), tensor([37], device='cuda:0')]\n",
      " [tensor([60], device='cuda:0'), tensor([59], device='cuda:0'), tensor([35], device='cuda:0'), tensor([46], device='cuda:0'), tensor([50], device='cuda:0'), tensor([43], device='cuda:0'), tensor([40], device='cuda:0'), tensor([41], device='cuda:0'), tensor([37], device='cuda:0'), tensor([47], device='cuda:0'), tensor([72], device='cuda:0'), tensor([38], device='cuda:0')]\n",
      "\n",
      "Are the positions the same?\n",
      " [tensor([False], device='cuda:0'), tensor([False], device='cuda:0'), tensor([False], device='cuda:0'), tensor([False], device='cuda:0'), tensor([False], device='cuda:0'), tensor([False], device='cuda:0'), tensor([False], device='cuda:0'), tensor([False], device='cuda:0'), tensor([False], device='cuda:0'), tensor([False], device='cuda:0'), tensor([False], device='cuda:0'), tensor([False], device='cuda:0')]\n",
      "\n",
      "Are the positions the same?\n",
      " [tensor([True], device='cuda:0'), tensor([True], device='cuda:0'), tensor([True], device='cuda:0'), tensor([True], device='cuda:0'), tensor([True], device='cuda:0'), tensor([True], device='cuda:0'), tensor([True], device='cuda:0'), tensor([True], device='cuda:0'), tensor([True], device='cuda:0'), tensor([True], device='cuda:0'), tensor([True], device='cuda:0'), tensor([True], device='cuda:0')]\n",
      "\n",
      "And of supposed_bools, are they all True?  True\n"
     ]
    }
   ],
   "source": [
    "# This show the position of token sep before and after the modification of b_input_ids\n",
    "old_positions = [ (b_input_ids[i] == 102).nonzero(as_tuple=True)[0] for i in range(len(b_input_ids))]\n",
    "new_positions = [ (add_prediction_to_input(b_input_ids[i], current_prediction[i]) == 102).nonzero(as_tuple=True)[0] for i in range(len(b_input_ids))]\n",
    "print(f\"{old_positions}\\n {new_positions}\\n\")\n",
    "# The position shoudn't be the same\n",
    "\n",
    "bools = [old_positions[i] == new_positions[i] for i in range(len(old_positions))]\n",
    "print(f\"Are the positions the same?\\n {bools}\\n\")\n",
    "supposed_bools =[ old_positions[i] == new_positions[i] - 1 for i in range(len(old_positions))]\n",
    "print(f\"Are the positions the same?\\n {supposed_bools}\\n\")\n",
    "\n",
    "print(\"And of supposed_bools, are they all True? \", all(supposed_bools))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_input_ids = add_prediction_to_input_batch(b_input_ids, current_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict again the next point with the new input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# losses\n",
    "losses = 0\n",
    "print(\"We predict\")\n",
    "# Predict\n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    # move to device\n",
    "    b_input_ids = b_input_ids.to(device)\n",
    "    b_input_mask = b_input_mask.to(device)\n",
    "    b_labels = b_labels.to(device)\n",
    "\n",
    "    # Telling the model not to compute or store gradients, saving memory and\n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        # the ouputs are a tuple with the loss and the logits\n",
    "        # the losses are the item 0 of the tuple\n",
    "        # and the logits are the item 1 of the tuple\n",
    "        # The loss is computed with the CrossEntropyLoss\n",
    "\n",
    "    logits = outputs[0]\n",
    "    losses += outputs[0].mean().item()\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to(\"cpu\").numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    # we have to append  the max of the logits\n",
    "    # because the logits are the output of the softmax\n",
    "    # and the max of the logits is the class with the highest probability\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "    # Store the inputs\n",
    "\n",
    "    list_inputs_test.append(b_input_ids.tolist())\n",
    "\n",
    "print(\"DONE.\")\n",
    "\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print(\"Calculating Matthews Corr. Coef. for each batch...\")\n",
    "\n",
    "pred_label = []\n",
    "# compute the loss\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "    # The predictions for this batch are a 2-column ndarray (one column for \"0\"\n",
    "    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "    # in to a list of 0s and 1s.\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "    pred_label.append(pred_labels_i)\n",
    "    # Calculate and store the coef for this batch.\n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
    "    matthews_set.append(matthews)\n",
    "\n",
    "\n",
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "\n",
    "# Combine the inputs for each batch into a single list.\n",
    "flat_list_inputs_test = [item for sublist in list_inputs_test for item in sublist]\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print(\"MCC: %.3f\" % mcc)\n",
    "\n",
    "\n",
    "# compute the accuracy\n",
    "accuracy = (flat_true_labels == flat_predictions).mean()\n",
    "print(\"accuracy: %.3f\" % accuracy)\n",
    "\n",
    "# print the loss\n",
    "print(\"loss: %.3f\" % (losses / len(true_labels)))\n",
    "\n",
    "\n",
    "# save flat_list_inputs_test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
