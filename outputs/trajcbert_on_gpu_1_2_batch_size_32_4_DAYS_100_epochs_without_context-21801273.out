created virtual environment CPython3.10.2.final.0-64 in 986ms
  creator CPython3Posix(dest=/localscratch/daril.21801273.0/MYENV, clear=False, no_vcs_ignore=False, global=False)
  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/daril/.local/share/virtualenv)
    added seed packages: pip==23.0+computecanada, setuptools==68.1.2+computecanada, wheel==0.41.2+computecanada
  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2020/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2020/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.66.1+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2/torch-2.0.1+computecanada-cp310-cp310-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic/scikit_learn-1.3.0+computecanada-cp310-cp310-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/transformers-4.34.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.12.4+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/networkx-3.1+computecanada-py3-none-any.whl
Requirement already satisfied: typing-extensions in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023a/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (4.5.0+computecanada)
Requirement already satisfied: sympy in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023a/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (1.11.1+computecanada)
Requirement already satisfied: jinja2 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023a/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (3.1.2+computecanada)
Requirement already satisfied: scipy>=1.5.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023a/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.10.1+computecanada)
Requirement already satisfied: numpy>=1.21 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023a/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.24.2+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.3.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/threadpoolctl-3.2.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic/tokenizers-0.14.0+computecanada-cp310-cp310-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/huggingface_hub-0.18.0+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/regex-2023.8.8+computecanada-cp310-cp310-linux_x86_64.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic/safetensors-0.3.3+computecanada-cp310-cp310-linux_x86_64.whl
Requirement already satisfied: requests in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023a/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 4)) (2.28.2+computecanada)
Requirement already satisfied: packaging>=20.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/ipykernel/2023a/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 4)) (23.0+computecanada)
Requirement already satisfied: pyyaml>=5.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023a/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 4)) (6.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/fsspec-2023.9.2+computecanada-py3-none-any.whl
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/huggingface_hub-0.16.4+computecanada-py3-none-any.whl
Requirement already satisfied: MarkupSafe>=2.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023a/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 2)) (2.1.2+computecanada)
Requirement already satisfied: idna<4,>=2.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023a/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 4)) (3.4+computecanada)
Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023a/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 4)) (2022.12.7+computecanada)
Requirement already satisfied: charset-normalizer<4,>=2 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023a/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 4)) (3.0.1+computecanada)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023a/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 4)) (1.26.14+computecanada)
Requirement already satisfied: mpmath>=0.19 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023a/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 2)) (1.2.1+computecanada)
Installing collected packages: safetensors, tqdm, threadpoolctl, regex, networkx, joblib, fsspec, filelock, torch, scikit-learn, huggingface-hub, tokenizers, transformers
Successfully installed filelock-3.12.4+computecanada fsspec-2023.9.2+computecanada huggingface-hub-0.16.4+computecanada joblib-1.3.2+computecanada networkx-3.1+computecanada regex-2023.8.8+computecanada safetensors-0.3.3+computecanada scikit-learn-1.3.0+computecanada threadpoolctl-3.2.0+computecanada tokenizers-0.14.0+computecanada torch-2.0.1+computecanada tqdm-4.66.1+computecanada transformers-4.34.0+computecanada
Package                            Version
---------------------------------- -----------------------
anyio                              3.6.2+computecanada
arff                               0.9+computecanada
argon2_cffi                        21.3.0+computecanada
argon2_cffi_bindings               21.2.0+computecanada
asttokens                          2.2.1+computecanada
async_generator                    1.10+computecanada
attrs                              22.2.0+computecanada
backcall                           0.2.0+computecanada
backports-abc                      0.5+computecanada
backports.shutil_get_terminal_size 1.0.0+computecanada
bcrypt                             4.0.1+computecanada
beautifulsoup4                     4.11.2+computecanada
bitstring                          4.0.1+computecanada
bleach                             6.0.0+computecanada
certifi                            2022.12.7+computecanada
cffi                               1.15.1+computecanada
chardet                            5.1.0+computecanada
charset_normalizer                 3.0.1+computecanada
comm                               0.1.2+computecanada
contourpy                          1.0.7+computecanada
cryptography                       39.0.1+computecanada
cycler                             0.11.0+computecanada
Cython                             0.29.33+computecanada
deap                               1.3.3+computecanada
debugpy                            1.6.6+computecanada
decorator                          5.1.1+computecanada
defusedxml                         0.7.1+computecanada
dnspython                          2.3.0+computecanada
ecdsa                              0.18.0+computecanada
entrypoints                        0.4+computecanada
executing                          1.2.0+computecanada
fastjsonschema                     2.16.2+computecanada
filelock                           3.12.4+computecanada
fonttools                          4.38.0+computecanada
fsspec                             2023.9.2+computecanada
funcsigs                           1.0.2+computecanada
huggingface_hub                    0.16.4+computecanada
idna                               3.4+computecanada
importlib_metadata                 5.2.0+computecanada
importlib_resources                5.12.0+computecanada
ipykernel                          6.21.2+computecanada
ipython                            8.10.0+computecanada
ipython_genutils                   0.2.0+computecanada
ipywidgets                         8.0.4+computecanada
jedi                               0.18.2+computecanada
Jinja2                             3.1.2+computecanada
joblib                             1.3.2+computecanada
jsonschema                         4.17.3+computecanada
jupyter_client                     8.0.3+computecanada
jupyter_core                       5.2.0+computecanada
jupyter_events                     0.6.3+computecanada
jupyter_server                     2.3.0+computecanada
jupyter_server_terminals           0.4.4+computecanada
jupyterlab_pygments                0.2.2+computecanada
jupyterlab_widgets                 3.0.5+computecanada
kiwisolver                         1.4.4+computecanada
lockfile                           0.12.2+computecanada
MarkupSafe                         2.1.2+computecanada
matplotlib                         3.7.0+computecanada
matplotlib_inline                  0.1.6+computecanada
mistune                            2.0.5+computecanada
mock                               5.0.1+computecanada
mpmath                             1.2.1+computecanada
nbclassic                          0.5.2+computecanada
nbclient                           0.7.2+computecanada
nbconvert                          7.2.9+computecanada
nbformat                           5.7.3+computecanada
nest_asyncio                       1.5.6+computecanada
netaddr                            0.8.0+computecanada
netifaces                          0.11.0+computecanada
networkx                           3.1+computecanada
nose                               1.3.7+computecanada
notebook                           6.5.2+computecanada
notebook_shim                      0.2.2+computecanada
numpy                              1.24.2+computecanada
packaging                          23.0+computecanada
pandas                             1.5.3+computecanada
pandocfilters                      1.5.0+computecanada
paramiko                           3.0.0+computecanada
parso                              0.8.3+computecanada
path                               16.6.0+computecanada
path.py                            12.5.0+computecanada
pathlib2                           2.3.7+computecanada
paycheck                           1.0.2+computecanada
pbr                                5.11.1+computecanada
pexpect                            4.8.0+computecanada
pickleshare                        0.7.5+computecanada
Pillow                             9.4.0+computecanada
pip                                23.0+computecanada
pkgutil_resolve_name               1.3.10+computecanada
platformdirs                       2.5.2+computecanada
prometheus_client                  0.16.0+computecanada
prompt_toolkit                     3.0.37+computecanada
psutil                             5.9.4+computecanada
ptyprocess                         0.7.0+computecanada
pure_eval                          0.2.2+computecanada
pycparser                          2.21+computecanada
Pygments                           2.14.0+computecanada
PyNaCl                             1.5.0+computecanada
pyparsing                          3.0.9+computecanada
pyrsistent                         0.19.3+computecanada
python-dateutil                    2.8.2+computecanada
python_json_logger                 2.0.7+computecanada
pytz                               2022.7.1+computecanada
PyYAML                             6.0+computecanada
pyzmq                              25.0.0+computecanada
regex                              2023.8.8+computecanada
requests                           2.28.2+computecanada
rfc3339_validator                  0.1.4+computecanada
rfc3986_validator                  0.1.1+computecanada
safetensors                        0.3.3+computecanada
scikit_learn                       1.3.0+computecanada
scipy                              1.10.1+computecanada
Send2Trash                         1.8.0+computecanada
setuptools                         68.1.2+computecanada
simplegeneric                      0.8.1+computecanada
singledispatch                     4.0.0+computecanada
six                                1.16.0+computecanada
sniffio                            1.3.0+computecanada
soupsieve                          2.4+computecanada
stack_data                         0.6.2+computecanada
sympy                              1.11.1+computecanada
terminado                          0.17.1+computecanada
testpath                           0.6.0+computecanada
threadpoolctl                      3.2.0+computecanada
tinycss2                           1.2.1+computecanada
tokenizers                         0.14.0+computecanada
torch                              2.0.1+computecanada
tornado                            6.2+computecanada
tqdm                               4.66.1+computecanada
traitlets                          5.9.0+computecanada
transformers                       4.34.0+computecanada
typing_extensions                  4.5.0+computecanada
urllib3                            1.26.14+computecanada
wcwidth                            0.2.6+computecanada
webencodings                       0.5.1+computecanada
websocket_client                   1.5.1+computecanada
wheel                              0.41.2+computecanada
widgetsnbextension                 4.0.5+computecanada
zipp                               3.14.0+computecanada
Data conversion to tensors...

[GPU0] Epoch 0 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 0 | Average loss: 4.550502496812836
  Validation Loss: 2.3687
Epoch 0 | Training checkpoint saved at /home/daril/scratch/data/trajcbert/models/model_saved_parallel_version_1_2_bs_32_100_epochs_without_context/checkpoints/checkpoint_epoch_0.pt
Epoch 0 | Best validation loss: 2.368670931161022
[GPU0] Epoch 1 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 1 | Average loss: 2.2400171229863735
  Validation Loss: 1.4233
Epoch 1 | Training checkpoint saved at /home/daril/scratch/data/trajcbert/models/model_saved_parallel_version_1_2_bs_32_100_epochs_without_context/checkpoints/checkpoint_epoch_1.pt
Epoch 1 | Best validation loss: 1.423294889992693
[GPU0] Epoch 2 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 2 | Average loss: 1.3877885615637482
  Validation Loss: 1.1107
Epoch 2 | Training checkpoint saved at /home/daril/scratch/data/trajcbert/models/model_saved_parallel_version_1_2_bs_32_100_epochs_without_context/checkpoints/checkpoint_epoch_2.pt
Epoch 2 | Best validation loss: 1.1106585495302637
[GPU0] Epoch 3 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 3 | Average loss: 1.0670351626243404
  Validation Loss: 0.9660
Epoch 3 | Training checkpoint saved at /home/daril/scratch/data/trajcbert/models/model_saved_parallel_version_1_2_bs_32_100_epochs_without_context/checkpoints/checkpoint_epoch_3.pt
Epoch 3 | Best validation loss: 0.9660152517001711
[GPU0] Epoch 4 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 4 | Average loss: 0.8848702560811472
  Validation Loss: 0.8793
Epoch 4 | Training checkpoint saved at /home/daril/scratch/data/trajcbert/models/model_saved_parallel_version_1_2_bs_32_100_epochs_without_context/checkpoints/checkpoint_epoch_4.pt
Epoch 4 | Best validation loss: 0.8793093626192573
[GPU0] Epoch 5 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 5 | Average loss: 0.7603791230469433
  Validation Loss: 0.8444
Epoch 5 | Training checkpoint saved at /home/daril/scratch/data/trajcbert/models/model_saved_parallel_version_1_2_bs_32_100_epochs_without_context/checkpoints/checkpoint_epoch_5.pt
Epoch 5 | Best validation loss: 0.8443560284596373
[GPU0] Epoch 6 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 6 | Average loss: 0.6777062433399895
  Validation Loss: 0.8141
Epoch 6 | Training checkpoint saved at /home/daril/scratch/data/trajcbert/models/model_saved_parallel_version_1_2_bs_32_100_epochs_without_context/checkpoints/checkpoint_epoch_6.pt
Epoch 6 | Best validation loss: 0.8140619519075483
[GPU0] Epoch 7 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 7 | Average loss: 0.601890601627783
  Validation Loss: 0.8000
Epoch 7 | Training checkpoint saved at /home/daril/scratch/data/trajcbert/models/model_saved_parallel_version_1_2_bs_32_100_epochs_without_context/checkpoints/checkpoint_epoch_7.pt
Epoch 7 | Best validation loss: 0.8000365589207284
[GPU0] Epoch 8 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 8 | Average loss: 0.5396428537585235
  Validation Loss: 0.7987
Epoch 8 | Training checkpoint saved at /home/daril/scratch/data/trajcbert/models/model_saved_parallel_version_1_2_bs_32_100_epochs_without_context/checkpoints/checkpoint_epoch_8.pt
Epoch 8 | Best validation loss: 0.7987472302925678
[GPU0] Epoch 9 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 9 | Average loss: 0.4892204938815595
  Validation Loss: 0.8015
[GPU0] Epoch 10 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 10 | Average loss: 0.44120070446400234
  Validation Loss: 0.8205
[GPU0] Epoch 11 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 11 | Average loss: 0.4056268171582104
  Validation Loss: 0.8251
[GPU0] Epoch 12 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 12 | Average loss: 0.3686920484613767
  Validation Loss: 0.8486
[GPU0] Epoch 13 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 13 | Average loss: 0.3383558803419153
  Validation Loss: 0.8703
[GPU0] Epoch 14 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 14 | Average loss: 0.31007105893608017
  Validation Loss: 0.8949
[GPU0] Epoch 15 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 15 | Average loss: 0.28685123430892395
  Validation Loss: 0.9166
[GPU0] Epoch 16 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 16 | Average loss: 0.2662502470554994
  Validation Loss: 0.9376
[GPU0] Epoch 17 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 17 | Average loss: 0.24981843185119978
  Validation Loss: 0.9655
[GPU0] Epoch 18 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 18 | Average loss: 0.23179321185687282
  Validation Loss: 0.9814
[GPU0] Epoch 19 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 19 | Average loss: 0.21637379799360798
  Validation Loss: 1.0030
[GPU0] Epoch 20 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 20 | Average loss: 0.2066478260867091
  Validation Loss: 1.0213
[GPU0] Epoch 21 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 21 | Average loss: 0.19365463897652618
  Validation Loss: 1.0430
[GPU0] Epoch 22 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 22 | Average loss: 0.1813280152148208
  Validation Loss: 1.0578
[GPU0] Epoch 23 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 23 | Average loss: 0.17315362729424208
  Validation Loss: 1.0672
[GPU0] Epoch 24 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 24 | Average loss: 0.16323373725317156
  Validation Loss: 1.0834
[GPU0] Epoch 25 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 25 | Average loss: 0.15727930129370604
  Validation Loss: 1.0962
[GPU0] Epoch 26 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 26 | Average loss: 0.14967812725063492
  Validation Loss: 1.1154
[GPU0] Epoch 27 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 27 | Average loss: 0.14064793773917258
  Validation Loss: 1.1188
[GPU0] Epoch 28 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 28 | Average loss: 0.13526455214918184
  Validation Loss: 1.1509
[GPU0] Epoch 29 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 29 | Average loss: 0.1295431498689426
  Validation Loss: 1.1557
[GPU0] Epoch 30 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 30 | Average loss: 0.12279300801119244
  Validation Loss: 1.1523
[GPU0] Epoch 31 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 31 | Average loss: 0.11872909866512193
  Validation Loss: 1.1772
[GPU0] Epoch 32 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 32 | Average loss: 0.1122429687923151
  Validation Loss: 1.1790
[GPU0] Epoch 33 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 33 | Average loss: 0.10978540576429825
  Validation Loss: 1.1979
[GPU0] Epoch 34 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 34 | Average loss: 0.10467303529388308
  Validation Loss: 1.1966
[GPU0] Epoch 35 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 35 | Average loss: 0.09862952498216881
  Validation Loss: 1.2107
[GPU0] Epoch 36 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 36 | Average loss: 0.0962128346202237
  Validation Loss: 1.2279
[GPU0] Epoch 37 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 37 | Average loss: 0.09347240985871798
  Validation Loss: 1.2370
[GPU0] Epoch 38 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 38 | Average loss: 0.08962747548863176
  Validation Loss: 1.2305
[GPU0] Epoch 39 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 39 | Average loss: 0.08706941833152831
  Validation Loss: 1.2464
[GPU0] Epoch 40 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 40 | Average loss: 0.08233994970778254
  Validation Loss: 1.2590
[GPU0] Epoch 41 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 41 | Average loss: 0.07902825935144289
  Validation Loss: 1.2731
[GPU0] Epoch 42 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 42 | Average loss: 0.07436799613355938
  Validation Loss: 1.2878
[GPU0] Epoch 43 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 43 | Average loss: 0.07128341873213148
  Validation Loss: 1.2980
[GPU0] Epoch 44 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 44 | Average loss: 0.06978405801755767
  Validation Loss: 1.3099
[GPU0] Epoch 45 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 45 | Average loss: 0.0682971832588686
  Validation Loss: 1.3120
[GPU0] Epoch 46 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 46 | Average loss: 0.0641005244104316
  Validation Loss: 1.3161
[GPU0] Epoch 47 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 47 | Average loss: 0.06344053547230626
  Validation Loss: 1.3348
[GPU0] Epoch 48 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 48 | Average loss: 0.06105281225727315
  Validation Loss: 1.3409
[GPU0] Epoch 49 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 49 | Average loss: 0.058519450206550035
  Validation Loss: 1.3400
[GPU0] Epoch 50 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 50 | Average loss: 0.0564178358926855
  Validation Loss: 1.3581
[GPU0] Epoch 51 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 51 | Average loss: 0.05451743330130748
  Validation Loss: 1.3709
[GPU0] Epoch 52 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 52 | Average loss: 0.05264442507447025
  Validation Loss: 1.3714
[GPU0] Epoch 53 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 53 | Average loss: 0.05173665078827142
  Validation Loss: 1.3754
[GPU0] Epoch 54 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 54 | Average loss: 0.049689555937319906
  Validation Loss: 1.3944
[GPU0] Epoch 55 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 55 | Average loss: 0.046052322518536894
  Validation Loss: 1.3970
[GPU0] Epoch 56 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 56 | Average loss: 0.04565496095523355
  Validation Loss: 1.4057
[GPU0] Epoch 57 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 57 | Average loss: 0.0465690313971699
  Validation Loss: 1.4072
[GPU0] Epoch 58 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 58 | Average loss: 0.04201488369504821
  Validation Loss: 1.4214
[GPU0] Epoch 59 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 59 | Average loss: 0.04210550218642075
  Validation Loss: 1.4090
[GPU0] Epoch 60 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 60 | Average loss: 0.04009699533345488
  Validation Loss: 1.4146
[GPU0] Epoch 61 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 61 | Average loss: 0.038667275139480844
  Validation Loss: 1.4247
[GPU0] Epoch 62 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 62 | Average loss: 0.037472941220619345
  Validation Loss: 1.4457
[GPU0] Epoch 63 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 63 | Average loss: 0.03671954464759962
  Validation Loss: 1.4514
[GPU0] Epoch 64 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 64 | Average loss: 0.03439013690880616
  Validation Loss: 1.4581
[GPU0] Epoch 65 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 65 | Average loss: 0.03386054733332442
  Validation Loss: 1.4582
[GPU0] Epoch 66 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 66 | Average loss: 0.0317158400756893
  Validation Loss: 1.4642
[GPU0] Epoch 67 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 67 | Average loss: 0.031154229929715886
  Validation Loss: 1.4704
[GPU0] Epoch 68 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 68 | Average loss: 0.03146212150857928
  Validation Loss: 1.4749
[GPU0] Epoch 69 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 69 | Average loss: 0.02922325679609622
  Validation Loss: 1.4833
[GPU0] Epoch 70 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 70 | Average loss: 0.02775545234399902
  Validation Loss: 1.4874
[GPU0] Epoch 71 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 71 | Average loss: 0.02818095435221834
  Validation Loss: 1.4978
[GPU0] Epoch 72 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 72 | Average loss: 0.0263424981193296
  Validation Loss: 1.4939
[GPU0] Epoch 73 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 73 | Average loss: 0.025667922566018322
  Validation Loss: 1.5052
[GPU0] Epoch 74 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 74 | Average loss: 0.024047565173355417
  Validation Loss: 1.4985
[GPU0] Epoch 75 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 75 | Average loss: 0.02431651548041053
  Validation Loss: 1.4989
[GPU0] Epoch 76 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 76 | Average loss: 0.023093275010264747
  Validation Loss: 1.5141
[GPU0] Epoch 77 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 77 | Average loss: 0.022650483175336654
  Validation Loss: 1.5113
[GPU0] Epoch 78 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 78 | Average loss: 0.020666642181133576
  Validation Loss: 1.5181
[GPU0] Epoch 79 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 79 | Average loss: 0.020223995766111093
  Validation Loss: 1.5250
[GPU0] Epoch 80 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 80 | Average loss: 0.01943134490026499
  Validation Loss: 1.5236
[GPU0] Epoch 81 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 81 | Average loss: 0.019405772325078587
  Validation Loss: 1.5309
[GPU0] Epoch 82 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 82 | Average loss: 0.018632509814586588
  Validation Loss: 1.5349
[GPU0] Epoch 83 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 83 | Average loss: 0.01764234372018239
  Validation Loss: 1.5255
[GPU0] Epoch 84 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 84 | Average loss: 0.017964915245682483
  Validation Loss: 1.5313
[GPU0] Epoch 85 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 85 | Average loss: 0.016024612561693824
  Validation Loss: 1.5434
[GPU0] Epoch 86 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 86 | Average loss: 0.015399766905295991
  Validation Loss: 1.5493
[GPU0] Epoch 87 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 87 | Average loss: 0.014967984412823739
  Validation Loss: 1.5461
[GPU0] Epoch 88 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 88 | Average loss: 0.014398329269036588
  Validation Loss: 1.5463
[GPU0] Epoch 89 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 89 | Average loss: 0.013618187971209061
  Validation Loss: 1.5553
[GPU0] Epoch 90 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 90 | Average loss: 0.012871771744550281
  Validation Loss: 1.5560
[GPU0] Epoch 91 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 91 | Average loss: 0.012780674616961413
  Validation Loss: 1.5554
[GPU0] Epoch 92 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 92 | Average loss: 0.01245317435640768
  Validation Loss: 1.5510
[GPU0] Epoch 93 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 93 | Average loss: 0.0118863892881787
  Validation Loss: 1.5568
[GPU0] Epoch 94 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 94 | Average loss: 0.010978276694441982
  Validation Loss: 1.5628
[GPU0] Epoch 95 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 95 | Average loss: 0.010508255817444401
  Validation Loss: 1.5608
[GPU0] Epoch 96 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 96 | Average loss: 0.01014213766446603
  Validation Loss: 1.5608
[GPU0] Epoch 97 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 97 | Average loss: 0.011162568779864686
  Validation Loss: 1.5617
[GPU0] Epoch 98 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 98 | Average loss: 0.01016118715963074
  Validation Loss: 1.5594
[GPU0] Epoch 99 | Batchsize: 32 | Steps: 4688
[GPU0] Epoch 99 | Average loss: 0.00937419294142202
  Validation Loss: 1.5604
Data conversion to tensors...

[GPU2] Epoch 0 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 0 | Average loss: 4.549839539523316
[GPU2] Epoch 1 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 1 | Average loss: 1.7103929261362287
[GPU2] Epoch 2 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 2 | Average loss: 1.1074578886654596
[GPU2] Epoch 3 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 3 | Average loss: 0.84060897824987
[GPU2] Epoch 4 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 4 | Average loss: 0.6863170252149804
[GPU2] Epoch 5 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 5 | Average loss: 0.584861551605343
[GPU2] Epoch 6 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 6 | Average loss: 0.49170051549431
[GPU2] Epoch 7 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 7 | Average loss: 0.4199405804724646
[GPU2] Epoch 8 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 8 | Average loss: 0.3616058845804057
[GPU2] Epoch 9 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 9 | Average loss: 0.30317183589894936
[GPU2] Epoch 10 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 10 | Average loss: 0.2575693708417759
[GPU2] Epoch 11 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 11 | Average loss: 0.21465881853050522
[GPU2] Epoch 12 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 12 | Average loss: 0.1806647192997502
[GPU2] Epoch 13 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 13 | Average loss: 0.15462983851325016
[GPU2] Epoch 14 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 14 | Average loss: 0.12893682500365772
[GPU2] Epoch 15 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 15 | Average loss: 0.10814956960458239
[GPU2] Epoch 16 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 16 | Average loss: 0.09159316004348486
[GPU2] Epoch 17 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 17 | Average loss: 0.07641116162369095
[GPU2] Epoch 18 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 18 | Average loss: 0.06707103332602371
[GPU2] Epoch 19 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 19 | Average loss: 0.05948925858323578
[GPU2] Epoch 20 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 20 | Average loss: 0.05152581301406534
[GPU2] Epoch 21 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 21 | Average loss: 0.045693884477752966
[GPU2] Epoch 22 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 22 | Average loss: 0.040424811375667516
[GPU2] Epoch 23 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 23 | Average loss: 0.036373851008526706
[GPU2] Epoch 24 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 24 | Average loss: 0.03248690810874415
[GPU2] Epoch 25 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 25 | Average loss: 0.029484910074025556
[GPU2] Epoch 26 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 26 | Average loss: 0.02588648789846817
[GPU2] Epoch 27 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 27 | Average loss: 0.02417920239020116
[GPU2] Epoch 28 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 28 | Average loss: 0.02038821103567575
[GPU2] Epoch 29 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 29 | Average loss: 0.01848145107759881
[GPU2] Epoch 30 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 30 | Average loss: 0.017798751089489983
[GPU2] Epoch 31 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 31 | Average loss: 0.015854100483368248
[GPU2] Epoch 32 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 32 | Average loss: 0.014280446158877892
[GPU2] Epoch 33 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 33 | Average loss: 0.013537145233426025
[GPU2] Epoch 34 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 34 | Average loss: 0.011989870337738746
[GPU2] Epoch 35 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 35 | Average loss: 0.011417493793667702
[GPU2] Epoch 36 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 36 | Average loss: 0.010263154974617815
[GPU2] Epoch 37 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 37 | Average loss: 0.008927697720242366
[GPU2] Epoch 38 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 38 | Average loss: 0.00845919391490606
[GPU2] Epoch 39 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 39 | Average loss: 0.007823748570727347
[GPU2] Epoch 40 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 40 | Average loss: 0.007432645349454168
[GPU2] Epoch 41 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 41 | Average loss: 0.006530470520479904
[GPU2] Epoch 42 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 42 | Average loss: 0.005955756546489519
[GPU2] Epoch 43 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 43 | Average loss: 0.005629671987814832
[GPU2] Epoch 44 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 44 | Average loss: 0.004921709559383542
[GPU2] Epoch 45 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 45 | Average loss: 0.005152988315906538
[GPU2] Epoch 46 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 46 | Average loss: 0.0043473070110613314
[GPU2] Epoch 47 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 47 | Average loss: 0.00421689335664281
[GPU2] Epoch 48 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 48 | Average loss: 0.0037087465303314994
[GPU2] Epoch 49 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 49 | Average loss: 0.0038153386390040894
[GPU2] Epoch 50 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 50 | Average loss: 0.0032630189170446884
[GPU2] Epoch 51 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 51 | Average loss: 0.0030994597456776734
[GPU2] Epoch 52 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 52 | Average loss: 0.0027967228081683428
[GPU2] Epoch 53 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 53 | Average loss: 0.0026268162412544393
[GPU2] Epoch 54 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 54 | Average loss: 0.002571458188675384
[GPU2] Epoch 55 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 55 | Average loss: 0.002389595018024169
[GPU2] Epoch 56 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 56 | Average loss: 0.002370060805895034
[GPU2] Epoch 57 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 57 | Average loss: 0.002027909569508265
[GPU2] Epoch 58 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 58 | Average loss: 0.0022107424538805637
[GPU2] Epoch 59 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 59 | Average loss: 0.0019674548560377697
[GPU2] Epoch 60 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 60 | Average loss: 0.0016749171518561558
[GPU2] Epoch 61 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 61 | Average loss: 0.0017654228286864157
[GPU2] Epoch 62 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 62 | Average loss: 0.0016321209714342424
[GPU2] Epoch 63 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 63 | Average loss: 0.0017017805221475016
[GPU2] Epoch 64 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 64 | Average loss: 0.001458986395895185
[GPU2] Epoch 65 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 65 | Average loss: 0.001394079564507583
[GPU2] Epoch 66 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 66 | Average loss: 0.0011864043348762362
[GPU2] Epoch 67 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 67 | Average loss: 0.0011052465595728126
[GPU2] Epoch 68 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 68 | Average loss: 0.0011813205319475182
[GPU2] Epoch 69 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 69 | Average loss: 0.001160320742369689
[GPU2] Epoch 70 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 70 | Average loss: 0.0009651691443309185
[GPU2] Epoch 71 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 71 | Average loss: 0.0009570406999995947
[GPU2] Epoch 72 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 72 | Average loss: 0.0009168908085455384
[GPU2] Epoch 73 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 73 | Average loss: 0.0008427640283068375
[GPU2] Epoch 74 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 74 | Average loss: 0.0007798955155688048
[GPU2] Epoch 75 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 75 | Average loss: 0.0006798147334845078
[GPU2] Epoch 76 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 76 | Average loss: 0.0006944853524948714
[GPU2] Epoch 77 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 77 | Average loss: 0.0006463988246543751
[GPU2] Epoch 78 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 78 | Average loss: 0.0006907736876271561
[GPU2] Epoch 79 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 79 | Average loss: 0.0006248246877476049
[GPU2] Epoch 80 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 80 | Average loss: 0.0007311955698758774
[GPU2] Epoch 81 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 81 | Average loss: 0.0005478932325701083
[GPU2] Epoch 82 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 82 | Average loss: 0.000636924081763533
[GPU2] Epoch 83 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 83 | Average loss: 0.00048273492745260903
[GPU2] Epoch 84 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 84 | Average loss: 0.0005049607062945006
[GPU2] Epoch 85 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 85 | Average loss: 0.000458814974256171
[GPU2] Epoch 86 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 86 | Average loss: 0.0005175668817420348
[GPU2] Epoch 87 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 87 | Average loss: 0.0005068363344324861
[GPU2] Epoch 88 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 88 | Average loss: 0.0005216106124744608
[GPU2] Epoch 89 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 89 | Average loss: 0.00046657790980136004
[GPU2] Epoch 90 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 90 | Average loss: 0.000491768274867947
[GPU2] Epoch 91 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 91 | Average loss: 0.00038916529196822414
[GPU2] Epoch 92 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 92 | Average loss: 0.0004482710971272233
[GPU2] Epoch 93 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 93 | Average loss: 0.00044671578881484914
[GPU2] Epoch 94 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 94 | Average loss: 0.00042999289663103924
[GPU2] Epoch 95 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 95 | Average loss: 0.0004603242809419129
[GPU2] Epoch 96 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 96 | Average loss: 0.0004234889025791568
[GPU2] Epoch 97 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 97 | Average loss: 0.0004089405837908322
[GPU2] Epoch 98 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 98 | Average loss: 0.0003680281267376562
[GPU2] Epoch 99 | Batchsize: 32 | Steps: 4688
[GPU2] Epoch 99 | Average loss: 0.00042740883161312157
Data conversion to tensors...

[GPU1] Epoch 0 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 0 | Average loss: 4.539229043756227
[GPU1] Epoch 1 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 1 | Average loss: 1.7128761406962476
[GPU1] Epoch 2 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 2 | Average loss: 1.1041397724408695
[GPU1] Epoch 3 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 3 | Average loss: 0.8501305395400361
[GPU1] Epoch 4 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 4 | Average loss: 0.6903492253092547
[GPU1] Epoch 5 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 5 | Average loss: 0.577092585182485
[GPU1] Epoch 6 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 6 | Average loss: 0.4951787039616905
[GPU1] Epoch 7 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 7 | Average loss: 0.4221011478058142
[GPU1] Epoch 8 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 8 | Average loss: 0.3547823797154905
[GPU1] Epoch 9 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 9 | Average loss: 0.30616898475725
[GPU1] Epoch 10 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 10 | Average loss: 0.2575112108364479
[GPU1] Epoch 11 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 11 | Average loss: 0.21842853255361738
[GPU1] Epoch 12 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 12 | Average loss: 0.18169990992777482
[GPU1] Epoch 13 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 13 | Average loss: 0.15257599418279605
[GPU1] Epoch 14 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 14 | Average loss: 0.12774857574753598
[GPU1] Epoch 15 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 15 | Average loss: 0.1085089203119262
[GPU1] Epoch 16 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 16 | Average loss: 0.09260727720129114
[GPU1] Epoch 17 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 17 | Average loss: 0.0811948129028573
[GPU1] Epoch 18 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 18 | Average loss: 0.06819450716098092
[GPU1] Epoch 19 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 19 | Average loss: 0.058013227124332524
[GPU1] Epoch 20 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 20 | Average loss: 0.051503479301973375
[GPU1] Epoch 21 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 21 | Average loss: 0.04484618093238634
[GPU1] Epoch 22 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 22 | Average loss: 0.04098607306514168
[GPU1] Epoch 23 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 23 | Average loss: 0.03619893568995251
[GPU1] Epoch 24 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 24 | Average loss: 0.033289595099221955
[GPU1] Epoch 25 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 25 | Average loss: 0.028887426476789428
[GPU1] Epoch 26 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 26 | Average loss: 0.026185556040460335
[GPU1] Epoch 27 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 27 | Average loss: 0.023499825711911063
[GPU1] Epoch 28 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 28 | Average loss: 0.02121019941720271
[GPU1] Epoch 29 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 29 | Average loss: 0.01899972430918264
[GPU1] Epoch 30 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 30 | Average loss: 0.017685524573434006
[GPU1] Epoch 31 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 31 | Average loss: 0.016135077132778772
[GPU1] Epoch 32 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 32 | Average loss: 0.014192618149958584
[GPU1] Epoch 33 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 33 | Average loss: 0.012706105783176961
[GPU1] Epoch 34 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 34 | Average loss: 0.012326614063443668
[GPU1] Epoch 35 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 35 | Average loss: 0.011071078356890026
[GPU1] Epoch 36 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 36 | Average loss: 0.010097771811555
[GPU1] Epoch 37 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 37 | Average loss: 0.009090306920882668
[GPU1] Epoch 38 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 38 | Average loss: 0.008524314251525176
[GPU1] Epoch 39 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 39 | Average loss: 0.007992347996911283
[GPU1] Epoch 40 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 40 | Average loss: 0.006870575906461777
[GPU1] Epoch 41 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 41 | Average loss: 0.006674493284948761
[GPU1] Epoch 42 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 42 | Average loss: 0.005624466165195853
[GPU1] Epoch 43 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 43 | Average loss: 0.005803162873145105
[GPU1] Epoch 44 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 44 | Average loss: 0.005280885458027667
[GPU1] Epoch 45 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 45 | Average loss: 0.004797209724507511
[GPU1] Epoch 46 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 46 | Average loss: 0.004797054717733095
[GPU1] Epoch 47 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 47 | Average loss: 0.00435630137065628
[GPU1] Epoch 48 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 48 | Average loss: 0.003996147692578544
[GPU1] Epoch 49 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 49 | Average loss: 0.0038923779108013816
[GPU1] Epoch 50 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 50 | Average loss: 0.0035925482401450294
[GPU1] Epoch 51 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 51 | Average loss: 0.0033089618863702897
[GPU1] Epoch 52 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 52 | Average loss: 0.0030673028487374445
[GPU1] Epoch 53 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 53 | Average loss: 0.0027753417169185507
[GPU1] Epoch 54 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 54 | Average loss: 0.0025824319710446575
[GPU1] Epoch 55 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 55 | Average loss: 0.0022927620968710366
[GPU1] Epoch 56 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 56 | Average loss: 0.0021696194196287027
[GPU1] Epoch 57 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 57 | Average loss: 0.0020288248170464976
[GPU1] Epoch 58 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 58 | Average loss: 0.002163900297341337
[GPU1] Epoch 59 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 59 | Average loss: 0.0018698431443648737
[GPU1] Epoch 60 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 60 | Average loss: 0.001599992731622888
[GPU1] Epoch 61 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 61 | Average loss: 0.001686861191751399
[GPU1] Epoch 62 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 62 | Average loss: 0.0015902350733240972
[GPU1] Epoch 63 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 63 | Average loss: 0.0016253034471729352
[GPU1] Epoch 64 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 64 | Average loss: 0.0013932236761397985
[GPU1] Epoch 65 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 65 | Average loss: 0.0013900088448163212
[GPU1] Epoch 66 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 66 | Average loss: 0.0012067654017677955
[GPU1] Epoch 67 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 67 | Average loss: 0.0010732230163022546
[GPU1] Epoch 68 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 68 | Average loss: 0.0010998696205387804
[GPU1] Epoch 69 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 69 | Average loss: 0.0009718106378187776
[GPU1] Epoch 70 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 70 | Average loss: 0.00100211321858765
[GPU1] Epoch 71 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 71 | Average loss: 0.0008556333392759895
[GPU1] Epoch 72 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 72 | Average loss: 0.0008569564353010005
[GPU1] Epoch 73 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 73 | Average loss: 0.0009653573386306347
[GPU1] Epoch 74 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 74 | Average loss: 0.0007381112519992976
[GPU1] Epoch 75 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 75 | Average loss: 0.0007817138650931628
[GPU1] Epoch 76 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 76 | Average loss: 0.0006987517115900776
[GPU1] Epoch 77 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 77 | Average loss: 0.0006431637937321626
[GPU1] Epoch 78 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 78 | Average loss: 0.0006883181682751331
[GPU1] Epoch 79 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 79 | Average loss: 0.0006001911647613409
[GPU1] Epoch 80 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 80 | Average loss: 0.0005327486038731256
[GPU1] Epoch 81 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 81 | Average loss: 0.000614142562429527
[GPU1] Epoch 82 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 82 | Average loss: 0.0006315923614961523
[GPU1] Epoch 83 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 83 | Average loss: 0.0005714628399701528
[GPU1] Epoch 84 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 84 | Average loss: 0.0005240755564843432
[GPU1] Epoch 85 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 85 | Average loss: 0.0005740768931337285
[GPU1] Epoch 86 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 86 | Average loss: 0.0004738188843172231
[GPU1] Epoch 87 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 87 | Average loss: 0.0005057505782676589
[GPU1] Epoch 88 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 88 | Average loss: 0.0004907652500889787
[GPU1] Epoch 89 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 89 | Average loss: 0.000418962588709363
[GPU1] Epoch 90 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 90 | Average loss: 0.0004058501224618734
[GPU1] Epoch 91 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 91 | Average loss: 0.0004611098779097234
[GPU1] Epoch 92 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 92 | Average loss: 0.0005031845079939176
[GPU1] Epoch 93 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 93 | Average loss: 0.00042371160827304316
[GPU1] Epoch 94 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 94 | Average loss: 0.0004649980445170426
[GPU1] Epoch 95 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 95 | Average loss: 0.00042489938565887215
[GPU1] Epoch 96 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 96 | Average loss: 0.00044849602942516364
[GPU1] Epoch 97 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 97 | Average loss: 0.00037672165601075597
[GPU1] Epoch 98 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 98 | Average loss: 0.0003826069260404087
[GPU1] Epoch 99 | Batchsize: 32 | Steps: 4688
[GPU1] Epoch 99 | Average loss: 0.000370345385204484
Data conversion to tensors...

[GPU3] Epoch 0 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 0 | Average loss: 4.5446752039238865
[GPU3] Epoch 1 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 1 | Average loss: 1.7145519973869108
[GPU3] Epoch 2 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 2 | Average loss: 1.103113700330588
[GPU3] Epoch 3 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 3 | Average loss: 0.8384789547250437
[GPU3] Epoch 4 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 4 | Average loss: 0.6885577192221715
[GPU3] Epoch 5 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 5 | Average loss: 0.5778262267388251
[GPU3] Epoch 6 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 6 | Average loss: 0.4885361591455727
[GPU3] Epoch 7 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 7 | Average loss: 0.41936761361257563
[GPU3] Epoch 8 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 8 | Average loss: 0.35859982365481685
[GPU3] Epoch 9 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 9 | Average loss: 0.30200834863989234
[GPU3] Epoch 10 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 10 | Average loss: 0.25553772373064565
[GPU3] Epoch 11 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 11 | Average loss: 0.21466632520163323
[GPU3] Epoch 12 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 12 | Average loss: 0.18177808522772831
[GPU3] Epoch 13 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 13 | Average loss: 0.15085643701892626
[GPU3] Epoch 14 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 14 | Average loss: 0.12840487609149367
[GPU3] Epoch 15 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 15 | Average loss: 0.10870631391636681
[GPU3] Epoch 16 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 16 | Average loss: 0.09175531524960619
[GPU3] Epoch 17 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 17 | Average loss: 0.07867578394350845
[GPU3] Epoch 18 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 18 | Average loss: 0.06814650640079557
[GPU3] Epoch 19 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 19 | Average loss: 0.059284403699064
[GPU3] Epoch 20 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 20 | Average loss: 0.05191447969003375
[GPU3] Epoch 21 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 21 | Average loss: 0.04617418676217241
[GPU3] Epoch 22 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 22 | Average loss: 0.04062228569503752
[GPU3] Epoch 23 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 23 | Average loss: 0.03638185572193331
[GPU3] Epoch 24 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 24 | Average loss: 0.03206173220323359
[GPU3] Epoch 25 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 25 | Average loss: 0.029299015618044027
[GPU3] Epoch 26 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 26 | Average loss: 0.026328031685090177
[GPU3] Epoch 27 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 27 | Average loss: 0.023365292124846636
[GPU3] Epoch 28 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 28 | Average loss: 0.02164866891529428
[GPU3] Epoch 29 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 29 | Average loss: 0.019698819898522547
[GPU3] Epoch 30 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 30 | Average loss: 0.017629150144741486
[GPU3] Epoch 31 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 31 | Average loss: 0.015646367090842217
[GPU3] Epoch 32 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 32 | Average loss: 0.014523871732482008
[GPU3] Epoch 33 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 33 | Average loss: 0.013798104569437045
[GPU3] Epoch 34 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 34 | Average loss: 0.01232496659974952
[GPU3] Epoch 35 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 35 | Average loss: 0.011714925038164754
[GPU3] Epoch 36 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 36 | Average loss: 0.010449953329887946
[GPU3] Epoch 37 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 37 | Average loss: 0.009211530070785429
[GPU3] Epoch 38 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 38 | Average loss: 0.008307151012174283
[GPU3] Epoch 39 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 39 | Average loss: 0.007809598159599047
[GPU3] Epoch 40 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 40 | Average loss: 0.007293876654445084
[GPU3] Epoch 41 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 41 | Average loss: 0.006571424494496435
[GPU3] Epoch 42 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 42 | Average loss: 0.006554835734696781
[GPU3] Epoch 43 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 43 | Average loss: 0.005574220423802834
[GPU3] Epoch 44 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 44 | Average loss: 0.005295825801538355
[GPU3] Epoch 45 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 45 | Average loss: 0.004807437316153187
[GPU3] Epoch 46 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 46 | Average loss: 0.004901570479878284
[GPU3] Epoch 47 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 47 | Average loss: 0.004464969736154641
[GPU3] Epoch 48 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 48 | Average loss: 0.0040805189587631305
[GPU3] Epoch 49 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 49 | Average loss: 0.0039012764540228948
[GPU3] Epoch 50 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 50 | Average loss: 0.0033073608976257004
[GPU3] Epoch 51 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 51 | Average loss: 0.003061769930938352
[GPU3] Epoch 52 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 52 | Average loss: 0.0032298614202288787
[GPU3] Epoch 53 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 53 | Average loss: 0.003135561306854895
[GPU3] Epoch 54 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 54 | Average loss: 0.002594218523158614
[GPU3] Epoch 55 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 55 | Average loss: 0.0025695724907393276
[GPU3] Epoch 56 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 56 | Average loss: 0.002426868680026695
[GPU3] Epoch 57 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 57 | Average loss: 0.00232728015318925
[GPU3] Epoch 58 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 58 | Average loss: 0.001885281202515685
[GPU3] Epoch 59 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 59 | Average loss: 0.0018600494148652183
[GPU3] Epoch 60 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 60 | Average loss: 0.0019222538884925175
[GPU3] Epoch 61 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 61 | Average loss: 0.0016212358121858303
[GPU3] Epoch 62 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 62 | Average loss: 0.0014863895310216308
[GPU3] Epoch 63 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 63 | Average loss: 0.0013408045402806977
[GPU3] Epoch 64 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 64 | Average loss: 0.0015079055471537205
[GPU3] Epoch 65 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 65 | Average loss: 0.0012154130213873028
[GPU3] Epoch 66 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 66 | Average loss: 0.0013643694916817004
[GPU3] Epoch 67 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 67 | Average loss: 0.00123320544970577
[GPU3] Epoch 68 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 68 | Average loss: 0.0009189097839741
[GPU3] Epoch 69 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 69 | Average loss: 0.0010768971118710838
[GPU3] Epoch 70 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 70 | Average loss: 0.0009615078745564802
[GPU3] Epoch 71 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 71 | Average loss: 0.0008896776464157344
[GPU3] Epoch 72 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 72 | Average loss: 0.0008599772691510293
[GPU3] Epoch 73 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 73 | Average loss: 0.0008284551036486371
[GPU3] Epoch 74 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 74 | Average loss: 0.0007217170106560244
[GPU3] Epoch 75 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 75 | Average loss: 0.000796234864939039
[GPU3] Epoch 76 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 76 | Average loss: 0.0007448200418613243
[GPU3] Epoch 77 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 77 | Average loss: 0.0006891801561505107
[GPU3] Epoch 78 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 78 | Average loss: 0.0005953390148094572
[GPU3] Epoch 79 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 79 | Average loss: 0.0006468644257349961
[GPU3] Epoch 80 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 80 | Average loss: 0.0005662245973264902
[GPU3] Epoch 81 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 81 | Average loss: 0.00059363212980899
[GPU3] Epoch 82 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 82 | Average loss: 0.00044452225725024355
[GPU3] Epoch 83 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 83 | Average loss: 0.0004799041783840365
[GPU3] Epoch 84 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 84 | Average loss: 0.0005442224144830038
[GPU3] Epoch 85 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 85 | Average loss: 0.0005240608616864885
[GPU3] Epoch 86 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 86 | Average loss: 0.00044909899037234944
[GPU3] Epoch 87 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 87 | Average loss: 0.0004914439149073985
[GPU3] Epoch 88 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 88 | Average loss: 0.00045686509072978684
[GPU3] Epoch 89 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 89 | Average loss: 0.0004336146195395697
[GPU3] Epoch 90 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 90 | Average loss: 0.0004685192313457857
[GPU3] Epoch 91 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 91 | Average loss: 0.0004717462387860573
[GPU3] Epoch 92 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 92 | Average loss: 0.0003834764604286737
[GPU3] Epoch 93 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 93 | Average loss: 0.0004229617553475828
[GPU3] Epoch 94 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 94 | Average loss: 0.00036808811192099014
[GPU3] Epoch 95 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 95 | Average loss: 0.00039526697697144544
[GPU3] Epoch 96 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 96 | Average loss: 0.0003516910940137795
[GPU3] Epoch 97 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 97 | Average loss: 0.0003876544150356116
[GPU3] Epoch 98 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 98 | Average loss: 0.0004235580131989215
[GPU3] Epoch 99 | Batchsize: 32 | Steps: 4688
[GPU3] Epoch 99 | Average loss: 0.0004102706640456596
