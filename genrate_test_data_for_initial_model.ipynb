{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# DIR_INPUTS_IDS = (\n",
    "#     \"/home/daril/trajcbert/savings_for_parrallel_1_2/input_ids_f_833383.pkl\"\n",
    "# )\n",
    "# DIR_ATTENTION_MASKS = (\n",
    "#     \"/home/daril/trajcbert/savings_for_parrallel_1_2/attention_masks_833383_opti.pkl\"\n",
    "# )\n",
    "# DIR_TARGETS = \"/home/daril/trajcbert/savings_for_parrallel_1_2/targets_833383_opti.pkl\"\n",
    "# PRETRAINED_MODEL_NAME = (\n",
    "#     \"/home/daril/trajcbert/savings_for_parrallel_1_2/model_before_training_opti_833383\"\n",
    "# )\n",
    "# DATALOADER_DIR = \"/home/daril/trajcbert/savings/test_dataloader_833383.pt\"\n",
    "\n",
    "\n",
    "def save_test_data_loader(\n",
    "    input_ids_path,\n",
    "    attention_masks_path,\n",
    "    targets_path,\n",
    "    dataloader_dir,\n",
    "    batch_size=32,\n",
    "):\n",
    "    # load the lists saved in deb_train_gpu_parallel.py\n",
    "    # the lists saved full_inputs, inputs_ids, attention_masks and the targets in different files /home/daril_kw/data/input_ids.pkl, /home/daril_kw/data/attention_masks.pkl, /home/daril_kw/data/targets.pkl\n",
    "\n",
    "    with open(input_ids_path, \"rb\") as f:\n",
    "        input_ids = pickle.load(f)\n",
    "\n",
    "    with open(attention_masks_path, \"rb\") as f:\n",
    "        attention_masks = pickle.load(f)\n",
    "\n",
    "    with open(targets_path, \"rb\") as f:\n",
    "        targets = pickle.load(f)\n",
    "\n",
    "    targets_dict = {}\n",
    "    # create a dictionary to convert the targets to numbers\n",
    "    for i in range(len(targets)):\n",
    "        if targets[i] not in targets_dict:\n",
    "            targets_dict[targets[i]] = len(targets_dict)\n",
    "\n",
    "    targets_input = [targets_dict[targets[i]] for i in range(len(targets))]\n",
    "\n",
    "    train_data, test_data, train_targets, test_targets = train_test_split(\n",
    "        input_ids, targets_input, random_state=2023, test_size=0.2\n",
    "    )\n",
    "\n",
    "    # the two _ are for test data and test targets\n",
    "\n",
    "    train_masks, test_mask, _, _ = train_test_split(\n",
    "        attention_masks, targets_input, random_state=2023, test_size=0.2\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # we create the dataloader for the test data\n",
    "\n",
    "    test_inputs = torch.tensor(test_data)\n",
    "    test_labels = torch.tensor(test_targets)\n",
    "    test_masks = torch.tensor(test_mask)\n",
    "    test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "    test_sampler = SequentialSampler(\n",
    "        test_data\n",
    "    )  # we don't use the DistributedSampler here because the validation is on a CPU\n",
    "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "    # save the test dataloader\n",
    "\n",
    "    torch.save(test_dataloader, dataloader_dir)\n",
    "\n",
    "    return test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # recover the parameters\n",
    "    # --inputs_ids_path $DIR_INPUTS_IDS \\\n",
    "    # --attention_masks_path $DIR_ATTENTION_MASKS \\\n",
    "    # --targets_path $DIR_TARGETS \\\n",
    "    # --dataloader_dir $DATALOADER_DIR\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--inputs_ids_path\", type=str, help=\"path to the inputs ids\")\n",
    "    parser.add_argument(\n",
    "        \"--attention_masks_path\", type=str, help=\"path to the attention masks\"\n",
    "    )\n",
    "    parser.add_argument(\"--targets_path\", type=str, help=\"path to the targets\")\n",
    "    parser.add_argument(\"--dataloader_dir\", type=str, help=\"path to the dataloader\")\n",
    "    args = parser.parse_args()\n",
    "    DIR_INPUTS_IDS = args.inputs_ids_path\n",
    "    DIR_ATTENTION_MASKS = args.attention_masks_path\n",
    "    DIR_TARGETS = args.targets_path\n",
    "    DATALOADER_DIR = args.dataloader_dir\n",
    "\n",
    "    save_test_data_loader(\n",
    "        DIR_INPUTS_IDS,\n",
    "        DIR_ATTENTION_MASKS,\n",
    "        DIR_TARGETS,\n",
    "        DATALOADER_DIR,\n",
    "        batch_size=32,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "# with open(f\"/home/daril_kw/data/savings_for_60_rows/input_ids_full_opti_for_para_60.pkl\", 'wb') as fp:\n",
    "#     pickle.dump(input_ids, fp)\n",
    "# with open(f\"/home/daril_kw/data/savings_for_60_rows/attention_masks_full_opti_for_para_60.pkl\", 'wb') as fp:\n",
    "#     pickle.dump(attention_masks, fp)\n",
    "# with open(f\"/home/daril_kw/data/savings_for_60_rows/targets_full_opti_for_para_60.pkl\", 'wb') as fp:\n",
    "#     pickle.dump(targets, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f4efeafd6c0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "DIR_INPUTS_IDS =  \"/home/daril_kw/data/savings_for_60_rows/input_ids_full_opti_for_para_60.pkl\"\n",
    "DIR_ATTENTION_MASKS = \"/home/daril_kw/data/savings_for_60_rows/attention_masks_full_opti_for_para_60.pkl\"\n",
    "DIR_TARGETS = \"/home/daril_kw/data/savings_for_60_rows/targets_full_opti_for_para_60.pkl\"\n",
    "DATALOADER_DIR = \"/home/daril_kw/data/savings_for_60_rows/test_dataloader_60.pt\"\n",
    "\n",
    "save_test_data_loader(\n",
    "    DIR_INPUTS_IDS,\n",
    "    DIR_ATTENTION_MASKS,\n",
    "    DIR_TARGETS,\n",
    "    DATALOADER_DIR,\n",
    "    batch_size=32,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
